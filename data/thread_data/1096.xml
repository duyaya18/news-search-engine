<?xml version='1.0' encoding='utf-8'?>
<doc><id>1092</id><url>http://www.chinanews.com/cj/2023/11-15/10112509.shtml</url><title>李彦宏对大模型的冷热思考：模型太多应用太少</title><datatime>2023-11-15 18:48:00</datatime><body>	中新网深圳11月15日电(记者郑小红)“中国的大模型很多，但是基于大模型开发出来的AI原生应用却非常少。”15日，在与第25届高交会同期举办的深圳2023西丽湖论坛上，百度创始人、董事长兼首席执行官李彦宏在分享国内AI行业现状的两个“冷思考”和三个“热驱动”时表示。
	李彦宏在“冷思考”中指出，截至10月份，国内已经发布238个大模型，大模型太多，而模型之上开发的AI原生应用太少。他同时表示，许多行业、企业、甚至城市都想从头训练自己的专用大模型，但专用大模型没有智能涌现能力，价值非常有限。
	对于“热驱动”时，李彦宏表示，强大的基础大模型能驱动AI原生应用爆发，当前，最好的AI原生应用还没出现，“AI原生时代一定会有优秀的AI原生应用是基于这些大模型开发出来的”。与之相对，AI原生应用也会驱动模型、芯片等AI技术栈的发展，“只有通过更多的场景落地应用，才能够形成更大的数据飞轮，才能够让芯片做到够用和好用。”
	“我们需要100万量级的AI原生应用，但是不需要100个大模型。”李彦宏称，在全球市场上，AI原生应用正在成为主要趋势。
	李彦宏表示，“不断地重复开发基础大模型是对社会资源的极大浪费”，“由于没有智能涌现能力，专用大模型的价值非常有限。”李彦宏分析说，很多行业、企业甚至城市都在买卡、囤芯片，建智算中心，想从头训练自己的专用大模型，殊不知这样炼出来的大模型是没有智能涌现能力的。
	“智能涌现”即为大模型触类旁通的能力，也就是没有教过的东西，大模型也会，“只有当你的模型的参数规模足够大，训练数据量足够多并且能够不断投入，进行迭代，才能够产生智能涌现。”
	李彦宏认为，“大模型的产业化模式，应该是把基础模型的通用能力和行业领域的专有知识相结合。”也就是说，大模型套小模型，专用小模型反应快、成本低，大模型更智能，可以用来兜底。
	李彦宏表示，大模型有没有对互联网公司的DAU、时长、用户留存这些指标产生正向影响，有没有对企业的收入、利润、成本产生影响，才是问题的本质。
	他以百度文库举例，经过AI原生化重构后的百度文库，能够在1分钟内生成一个20几页的PPT，包括图表生成、格式美化等，而且几乎是零成本，实现了从内容工具到生产力工具的转变。
	他认为，AI原生的概念肯定会先被C端用户和创业公司接受，其次是中小企业，最后才是大企业。他表示，大公司分工明确，需要CEO主动引领变革。
	李彦宏认为，强大的基础大模型会驱动AI原生应用的爆发，“中国有领先的基础大模型，这是AI原生应用发展的坚实基础，是底层的能力。而只有通过更多的场景落地应用，才可以形成更大的数据飞轮，才能让芯片做到够用、好用。”李彦宏表示。(完)
</body><key_sentence>对于“热驱动”时，李彦宏表示，强大的基础大模型能驱动AI原生应用爆发，当前，最好的AI原生应用还没出现，“AI原生时代一定会有优秀的AI原生应用是基于这些大模型开发出来的”。李彦宏认为，强大的基础大模型会驱动AI原生应用的爆发，“中国有领先的基础大模型，这是AI原生应用发展的坚实基础，是底层的能力。”李彦宏分析说，很多行业、企业甚至城市都在买卡、囤芯片，建智算中心，想从头训练自己的专用大模型，殊不知这样炼出来的大模型是没有智能涌现能力的。与之相对，AI原生应用也会驱动模型、芯片等AI技术栈的发展，“只有通过更多的场景落地应用，才能够形成更大的数据飞轮，才能够让芯片做到够用和好用。</key_sentence></doc>