<?xml version='1.0' encoding='utf-8'?>
<doc><id>10096</id><url>http://www.chinanews.com/cj/2023/12-07/10123835.shtml</url><title>专家：须对AI技术进行制度规范和约束</title><datatime>2023-12-7 02:20:00</datatime><body>	针对用ChatGPT写论文所产生的便捷与风险并存情况，专家表示——
	须对AI技术进行制度规范和约束
	◎本报记者张晔
	以ChatGPT为代表的生成式人工智能技术，依靠其强大的文本生成能力，早已经无可避免地渗入到了写作领域。当人们还在惊叹于AI文章的流畅结构、精准表达之时，有一部分人已熟练地把ChatGPT当作撰写学术论文的工具。
	日前，江苏省科技厅监督评估处处长顾俊在做客江苏广电总台新闻频道《政风热线》时回应称，将组织开展科技人员公开发表论文的自查和抽查，并开展科技伦理审查，引导科技人员提高诚信意识。
	那么，ChatGPT等生成式人工智能技术究竟能否用于学术论文写作？如何防范AI技术滥用带来的学术不端现象？科技日报记者采访了相关主管部门工作人员和业内学者。
	产生的学术不端风险不容忽视
	不能否认，ChatGPT能生成连贯的、有逻辑性的文章，并给人们的工作和生活带来了便利。但是，由此产生的学术不端风险不容忽视。国外已有研究人员发现，ChatGPT所给的回答都是基于它模型训练的海量数据，有时可能会限制人们的思维，甚至有些回答并不准确，比如只选择有利于自己观点的数据进行佐证，忽视其他数据。
	12月1日，《科技伦理审查办法(试行)》正式实施，记者查询后并未在其中找到与生成式人工智能技术相关的条款。目前，国内相关部门和科研组织对ChatGPT写论文的规定还未明确细化，但是不论以何种方式，只要出现抄袭、剽窃、造假等学术不端行为，都是严查重罚的对象。
	11月24日，国家自然科学基金委员会公布了2023年第二批不端行为案件的调查处理结果，数量最多的不端行为是抄袭、剽窃、伪造各种信息，总数达15人，占比62.5%。记者了解到，国内已有省份对科研论文进行有针对性的抽查，重点检查抄袭、造假和重复发表等学术不端现象，虽然没有专门针对ChatGPT，但是这些问题都有可能与之相关。
	江苏省科技厅监督评估处相关负责人说，将进一步加强科技伦理审查。同时，要求各单位对所发表的学术论文进行学术不端问题自查和清理，科技部门不定期组织开展主动抽查工作，不断更新学术不端治理程序和标准。
	该负责人表示，防范AI技术滥用带来的学术不端，将是科技管理部门今后重点监管内容之一。目前，国内已有科研单位在开发相应软件，用于AI写论文的查重工作，今后想利用ChatGPT写论文获得荣誉奖励和科研项目将越来越难。
	如何面对避无可避的AI技术
	南京理工大学教授李千目，长期从事人工智能系统安全、大数据挖掘研究。在他看来，当人们在谈论AI技术所产生的负面影响时，更应当看到它们所带来的便捷与进步。
	“AI技术是科研辅助工具之一，它让我们对某个问题调研更便捷、分析更明确、研判更精细，资料收集和信息反馈更全面和完整，如果我们合理地运用这个工具，对科研成果(包括但不限于论文)的整体提升会有较大作用。”李千目解释说。
	那么，在实践中AI技术到底该如何更好地为科研工作服务，而不是成为抄袭造假的工具？
	李千目表示，首先要有制度规范，并约束AI技术的使用，比如12月1日起实施的《科技伦理审查办法(试行)》，它规定了科技工作者及其共同体应恪守的价值观念、社会责任和行为规范。希望对这些制度、标准进行广泛地宣贯，让更多的科研人员去了解、遵循。
	其次是提升社会各界对AI技术的认知。李千目认为，在人类社会和科学发展每个阶段，抄袭几乎无法完全避免，利用AI技术进行抄袭、剽窃并谋取某些利益，必须严厉打击。但是，提升人们对AI技术的认知并推广使用，有助于推动社会进步和技术发展。
	“比如利用AI广泛地采集信息，让我们的论点和思路更加可行、更加有效，这件事情本身不是坏事。”李千目说，面对海量数据，他们很难全面有效地收集所需信息，而AI工具可以更高效地完成这项工作。
	但出于各种原因，很多将AI用于科研论文的作者并不乐于披露这个事实。“我坚持认为，在论文写作和数据收集中使用到AI技术，必须在参考文献里进行标注。”李千目说。
	不难看出，AI在当下科研工作中已扮演重要角色。更重要的是，人们似乎也别无选择——面对AI，不必回避，也避无可避。
	目前，国外已有高校宣布解除ChatGPT使用禁令，并推出了详细的使用原则。因此，多位科研工作者向记者表示，对AI技术在科研工作中的使用不应一刀切地反对，也不能对AI带来的学术不端行为放任不管。(科技日报)
</body><key_sentence>因此，多位科研工作者向记者表示，对AI技术在科研工作中的使用不应一刀切地反对，也不能对AI带来的学术不端行为放任不管。李千目表示，首先要有制度规范，并约束AI技术的使用，比如12月1日起实施的《科技伦理审查办法(试行)》，它规定了科技工作者及其共同体应恪守的价值观念、社会责任和行为规范。记者了解到，国内已有省份对科研论文进行有针对性的抽查，重点检查抄袭、造假和重复发表等学术不端现象，虽然没有专门针对ChatGPT，但是这些问题都有可能与之相关。该负责人表示，防范AI技术滥用带来的学术不端，将是科技管理部门今后重点监管内容之一。</key_sentence></doc>