<?xml version='1.0' encoding='utf-8'?>
<doc><id>2871</id><url>http://www.chinanews.com/cj/2023/11-02/10104873.shtml</url><title>首个全球性AI声明：中国等28国、欧盟签署《布莱切利宣言》</title><datatime>2023-11-2 13:36:00</datatime><body>	·《布莱切利宣言》是全球第一份针对人工智能这一快速新兴技术的国际性声明，旨在关注对未来强大人工智能模型构成人类生存威胁的担忧，以及对人工智能当前增强有害或偏见信息的担忧。
	·英国媒体评价称，“这是罕见的全球团结表现”。但英美在监管的优先事项上存在差异，人工智能学界和业界也争论激烈。
	全球28个国家和欧盟一致认为，人工智能对人类构成了潜在的灾难性风险。
	11月1日，首届全球人工智能(AI)安全峰会在英国布莱切利庄园拉开帷幕。在开幕式上，由包括中国在内的与会国共同达成的《布莱切利宣言》正式发表。这是全球第一份针对人工智能这一快速新兴技术的国际性声明，旨在关注对未来强大人工智能模型构成人类生存威胁的担忧，以及对人工智能当前增强有害或偏见信息的担忧。
	据新华社报道，中国科技部副部长吴朝晖率团出席此次峰会，参与人工智能安全等问题讨论，积极宣介中方提出的《全球人工智能治理倡议》，并将与相关国家开展双边会谈。该倡议围绕人工智能发展、安全、治理三方面系统阐述了人工智能治理中国方案。
	中国科技部副部长吴朝晖发表讲话
	布莱切利庄园是二战期间盟军破译密码的主要地点。半个多世纪前，“现代计算机科学与人工智能之父”、数学家阿兰·图灵在那里发明了第一代图灵计算机。
	如今，英国科学、创新和技术大臣米歇尔·唐兰发表讲话宣布了《布莱切利宣言》。她说：“各国现在第一次一致认为，我们不仅需要各自面对，而且需要共同审视前沿人工智能的风险。”
	“我们申明，为了所有人的利益，人工智能应该以安全、以人为中心、值得信赖和负责任的方式设计、开发、部署和使用。”宣言写道，并特别呼吁人们关注OpenAI、Meta和谷歌等公司正在开发的大型语言模型，以及它们可能因滥用而造成的具体威胁。
	“人工智能的‘前沿’出现了特殊的安全风险，被理解为那些能力强大的通用人工智能模型，包括基础模型，它们可以执行各种各样的任务，以及相关的特定狭义人工智能，它们可以表现出以下能力：造成伤害——其能力达到或超过当今最先进模型的能力。”宣言指出。
	宣言尤其关注网络安全和生物技术等领域的风险，以及前沿AI可能放大虚假信息等风险。
	唐兰宣布，人工智能安全峰会将成为一项定期重复举行的活动，下一届峰会计划于6个月后在韩国举行，再下一届计划一年后在法国举行。
	吴朝晖在开幕式上发表了演讲。据新华社报道，中方指出，人工智能治理攸关全人类命运，是世界各国面临的共同课题。发展人工智能，应当积极倡导以人为本，智能向善，加强技术风险管控，并在相互尊重、平等互利的原则基础上，鼓励各方协同共治，增强发展中国家在人工智能全球治理中的代表性和发言权，不断弥合智能鸿沟和治理能力差距。中方愿与各方一道就人工智能安全治理加强沟通交流，为推动形成普遍参与的国际机制和具有广泛共识的治理框架积极贡献智慧，切实落实全球发展倡议、全球安全倡议和全球文明倡议，促进人工智能技术更好造福人类，共同构建人类命运共同体。
	峰会中也出现了一些具体进展。美国商务部长吉娜·雷蒙多宣布成立一个新的人工智能安全研究所，该研究所将设在美国商务部内，具体隶属于该部的国家标准与技术研究院(NIST)。雷蒙多说，该组织的目标是与其他政府设立的其他人工智能安全组织密切合作，并透露英国也计划建立安全研究所。“我们必须开始工作，我们的机构之间也必须开始努力，以在全球范围内实现政策一致。”她说。
	“罕见的全球团结表现”
	本次峰会邀请了约100名各国官员、人工智能企业代表和专家。英国科学、创新和技术部11月1日发布的信息显示，有美国、中国、日本、德国、印度等20多个国家的政府代表，以及联合国、经合组织、国际电信联盟等多个国际组织的代表参会。另有超过80个学术机构、企业和协会组织代表参会。
	据《环球时报》援引路透社报道，中国于上周接受了英方的参会邀请，与吴朝晖一道与会的还有来自中国外交部、企业和学术机构的代表。据新华社报道，中国科学院、中国腾讯公司、阿里巴巴公司出席了会议。外国科技企业中，微软总裁布拉德·史密斯、OpenAI首席执行官山姆·奥特曼、谷歌DeepMind首席执行官德米斯·哈萨比斯、特斯拉首席执行官埃隆·马斯克等出席峰会。
	英国媒体称，美国商务部长雷蒙多和中国科技部副部长吴朝晖与唐兰一起登台，“这是罕见的全球团结表现”。负责组织此次峰会的英国官员之一马特·克利福德(MattClifford)称，雷蒙多和吴朝晖一起出现在舞台上是“一个非凡的时刻”。此次峰会标志着英国尤其是英国首相苏纳克的外交成功。
	不过，美国媒体注意到，根据与会者的个人陈述，各国的优先事项存在一定差异。比如，一些学者和包括马斯克在内的人工智能开发者猜测“上帝般的”人工智能可能会消灭人类，在此推动下，苏纳克倾向于控制超能力的前沿模型，而《布莱切利宣言》也对这种理论上灭绝级别的威胁表示认可。
	相比之下，美国代表不同意这种优先事项，或者至少在同意的程度上不如英国。与会的美国副总统卡马拉·哈里斯更担心人工智能目前对社会构成的威胁。“让我们明确一点，还有其他威胁也需要我们采取行动。当前正在造成伤害的威胁，对许多人来说也感觉是存在的……”她表示。
	美国媒体POLICITO评论道，这种分歧并不是完全排除或忽视其中一种风险，正如《布莱切利宣言》对这两种风险都认可。但政府的政治资本和影响力都是有限的，而且它们决定关注的法规目前还远未确定。企业担心这种不确定性，一些公司对针对不同优先事项的监管法规可能会使他们的工作变得复杂化感到愤怒。Meta公司全球事务总裁尼克·克莱格(NickClegg)表示，世界各国政府监管人工智能的竞赛令整个行业感到困惑，希望本周的峰会至少能让各国政府“朝着类似的方向前进”。
	开幕全体会议上的领导人不仅包括来自世界最大经济体的代表，还有一些发展中国家的代表。他们谈到了包容性和责任感，但如何实施仍存在许多疑问。
	AI业界争论激烈
	一些开发人员、学者和活动人士担心，政府缺乏协调会导致科技巨头在竞争中肆意妄为，破坏保护隐私或消费者权益的概念。
	就在此次峰会召开前夕，图灵奖得主、“人工智能三巨头”等学者爆发了一场激烈争论。首先是三巨头中的杰弗里·辛顿(GeoffreyHinton)和约书亚·本吉奥(YoshuaBengio)呼吁加强对AI技术监管，否则可能引发危险的“AI末日论”，随后三巨头之一、Meta人工智能的负责人杨立昆(YannLeCun)警告说，“迅速采取错误的监管方式可能会导致以损害竞争和创新的方式集中权力。”斯坦福大学教授吴恩达加入杨立昆行列，称对末日论的过度恐惧正在造成真正的伤害，将粉碎开源，扼杀创新。
	10月25日，中国人工智能科学家与西方知名学者一道，呼吁对人工智能技术实施更严格的控制。这24名AI专家签署一份声明警告称，在未来几十年，先进的人工智能将对“人类的生存构成威胁”。清华大学交叉信息研究院院长姚期智、清华大学智能产业研究院院长张亚勤这两位知名中国学者均是签署者。他们呼吁建立一个国际监管机构，先进的人工智能系统须进行强制性注册和接受审核，引入即时“关闭”程序，并要求开发企业将30%的研究预算用于人工智能安全。《金融时报》11月1日称，这些提议初步表明了中国在全球人工智能监管方面可能采取的立场。
	在布莱切利庄园，马斯克在峰会期间提出了自己的建议。“我们来这里的真正目标是建立一个洞察框架，这样至少会有一个第三方裁判，一个独立的裁判，可以观察领先的AI公司在做什么，至少在他们有担忧时发出警报。”他认为，在政府采取监管行动之前，需要先了解AI的发展情况，AI领域的很多人都担心政府在知道该怎么做之前会过早地制定规则。
	一直以来对AI频频发出警报的马斯克说：“这是人类历史上第一次与远比我们聪明的东西共处，所以我不清楚，我们是否真的能控制这样的东西。但我认为我们可以期待的是，引导它朝着对人类有益的方向发展。我确实认为，这是我们面临的生存风险之一，而且可能是最紧迫的风险。”
	本次峰会历时两天，第一天由唐兰主持，大多数科技公司和政府官员将出席首日活动。第二天的会议则由苏纳克主持，只会邀请小部分政治领导人和科技高管讨论具体应对措施。（澎湃新闻记者方晓）【编辑:曹子健】
</body><key_sentence>·《布莱切利宣言》是全球第一份针对人工智能这一快速新兴技术的国际性声明，旨在关注对未来强大人工智能模型构成人类生存威胁的担忧，以及对人工智能当前增强有害或偏见信息的担忧。比如，一些学者和包括马斯克在内的人工智能开发者猜测“上帝般的”人工智能可能会消灭人类，在此推动下，苏纳克倾向于控制超能力的前沿模型，而《布莱切利宣言》也对这种理论上灭绝级别的威胁表示认可。11月1日，首届全球人工智能(AI)安全峰会在英国布莱切利庄园拉开帷幕。据新华社报道，中国科技部副部长吴朝晖率团出席此次峰会，参与人工智能安全等问题讨论，积极宣介中方提出的《全球人工智能治理倡议》，并将与相关国家开展双边会谈。</key_sentence></doc>