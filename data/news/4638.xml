<?xml version='1.0' encoding='utf-8'?>
<doc><id>4638</id><url>http://www.chinanews.com/sh/2023/11-10/10109492.shtml</url><title>防范AI诈骗需有新解</title><datatime>2023-11-10 05:07:00</datatime><body>	皇甫思逸、练洪洋
	今年上半年，有媒体曝光了一起诈骗案件，受害人遭遇AI换脸诈骗，10分钟被“好友”骗走430万元。近年来，AI换脸、换声视频在网络上流行起来，一些不法分子也开始利用其实施新型网络诈骗。（11月8日中国新闻网）
	新闻里提到的AI诈骗并非首例。AI视频诈骗、AI合成不雅视频勒索……各式新型诈骗手段层出不穷。当前，反诈宣传开展得如火如荼，群众的“免疫力”有所提高。但AI诈骗尤其值得警惕——它能够极为真实地模仿真人的模样和声音。一条短信不足以令人信服，那么电话里熟悉的声音或是直接拨来的视频通话呢？人们总说：“照片会骗人但视频不会。”AI视频如此以假乱真，让人不寒而栗。
	那么，AI合成的素材从何而来？互联网时代，不法分子能通过各种渠道获取我们的个人信息——社交平台的图文、各种网站搜集的照片、App强制开启后台权限等。有了信息基础，AI深度学习后，就能将目标人物的生物信息嫁接到特定的音频、视频中。因此，要想远离AI诈骗陷阱，首先个人要提高防范意识、保护隐私。其次，相关法律法规应跟进到位，严惩AI诈骗者，用高昂代价震慑不法分子，遏制其“野蛮生长”。
	自国家反诈中心成立以来，预警劝阻、防骗咨询等手段大大降低了电信诈骗发生率。上一秒刚接到诈骗电话，下一秒反诈短信和防骗电话就齐上阵了。如今，诈骗有了新手段，简单的肉眼识别防范不了愈发逼真的AI诈骗，治理部门该进一步思考监管执法方向，给出新解答。（广州日报）【编辑:曹子健】
</body><key_sentence>近年来，AI换脸、换声视频在网络上流行起来，一些不法分子也开始利用其实施新型网络诈骗。AI视频诈骗、AI合成不雅视频勒索。如今，诈骗有了新手段，简单的肉眼识别防范不了愈发逼真的AI诈骗，治理部门该进一步思考监管执法方向，给出新解答。今年上半年，有媒体曝光了一起诈骗案件，受害人遭遇AI换脸诈骗，10分钟被“好友”骗走430万元。</key_sentence></doc>