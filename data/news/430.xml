<?xml version='1.0' encoding='utf-8'?>
<doc><id>430</id><url>http://www.chinanews.com/cul/2023/10-20/10097438.shtml</url><title>AI会取代人类么？ 成都世界科幻大会上，科学家与科幻作家一起探讨</title><datatime>2023-10-20 11:19:00</datatime><body>	说到人工智能，就不得不谈到美国科幻小说黄金时代的代表人物艾萨克·阿西莫夫和他在20世纪40年代提出的机器人“三定律”。
	时隔八十余年后的今天，人工智能早已不再只是文学作品中的天马行空，战胜世界围棋冠军的阿尔法狗、聊天机器人程序ChatGPT、AI绘画软件等人工智能的诞生和惊人表现，在引发公众的震惊和赞美之余，也面临着海量质疑。
	人工智能的发展会不会失控？机器人三定律背后的逻辑足够缜密吗？它在人工智能新时代还适用吗？在19日于成都举办的2023成都世界科幻大会主题沙龙——“科幻与未来科学”现场，与会嘉宾进行了有趣的思维碰撞。
	机器人三定律背后的逻辑是否足够缜密？
	据了解，“三定律”具体包括：第一定律是机器人不得伤害人类个体，或者目睹人类个体遭遇危险却袖手旁观；第二定律是机器人必须服从人类给予它的命令，除非这一命令与第一定律相矛盾；第三定律是不违反第一定律和第二定律的前提下，机器人要尽可能地确保自己的生存。
	在人工智能科幻作品《造神年代》作者严曦看来，“三定律”本身的问题在于：语言本身是不包含三原则的，“把对机器人的约束标准放到非常抽象的语言层面，这只是人类的想法。因为机器人的语言和逻辑是很底层的，它会通过各种强行的细节解释去绕过这些定律。”这也是他之所以认为“三定律”可能对机器人约束性不够强，也不会被好好实施的原因。
	“这涉及到了下一代AI，或者说语言智能的发展到底会遵循一个怎样的路径。”中国科学技术大学信息科学与技术学院教授宋彦表示，这个问题实际上也是作为AI的研究者和从业者经常会被问到的一个问题。在其看来，从以往的经验来看，人类一直都在按照最拟人化的方式来构建人工智能系统，包括现在用巨量的参数推动去学习，其实都是在不同的方面来推动机器人往拟人的方向发展。“未来几年内，可能还是会遵循这样的路径。”
	在“不变”中，也有几个变化。宋彦举例，比如，人类的知识系统怎么去表达，以及自然语言跟其他模态的组合的发展。“下一步，可能在其他模态的辅助下，我们有效减少数据，就能达到想要的效果。再下一步，实现让机器人自己去思考。”而如果发展到这一步，机器人的发展可能就能达到今天我们想要它实现理解语言的效果了。
	AI融进我们的生活有很多可能它会不会取代人类？
	在未来，人类和AI是否能和谐共处？
	严曦认为，当我们谈到AI伦理，当前可能更需要约束的是AI的开发者，而不是AI本身。“在早前，当AI技术还不够成熟的时候，我们想到AI，总是从人的既定思维出发，把它想象成类人的东西。不管其形态、语言还是思维方式，都没有脱离人的轨道。但我们现在越来越清楚地看到，很可能将来的强人工智能不怎么像人，甚至跟人完全不同，其思维方式从底层开始就跟人分道扬镳，就可能出现有一天人类跟AI讲伦理的时候，已经讲不通了。”严曦认为更应该关注开发者们的道德观和伦理问题，“不要‘喂’给你的AI，这样会形成一个垃圾的无限循环，会把内容带到不可回归的歧路上。”
	“将AI融进我们的生活之中，将有很多种可能。”科幻作家、2024年格拉斯哥世界科幻大会主宾肯·麦克劳德举例说，有些人可能觉得使用AI做的艺术作品是没有灵魂的，但依然会有一些作品令人震惊。他提及，他曾读过一本科幻小说，在那本书中，每句话都能让AI产生一幅图画，这些画有不同的风格。当时他的心情十分复杂，“当我们去看这些图画的时候，确实能有一些呼唤，这是十分奇特的感觉。”一方面，他觉得对于这些艺术家来说，这其实也是一种威胁。但另一方面，他也可能会喜欢AI所写的科幻小说。
	美国科幻作家、雨果奖得主詹姆斯·帕特里克·凯利则认为，人类之间的经验是不可互换的，一个强大的AI有自己的体验，这个AI其实是处理了其他人的经验。长久以来，AI就会形成这样的习惯，去传达人类喜欢的信息。“这个我是十分支持的，因为我可以去读其他人写的作品。”(成都商报—红星新闻记者彭祥萍摄影记者王勤)【编辑:钱姣姣】
</body><key_sentence>”科幻作家、2024年格拉斯哥世界科幻大会主宾肯·麦克劳德举例说，有些人可能觉得使用AI做的艺术作品是没有灵魂的，但依然会有一些作品令人震惊。在人工智能科幻作品《造神年代》作者严曦看来，“三定律”本身的问题在于：语言本身是不包含三原则的，“把对机器人的约束标准放到非常抽象的语言层面，这只是人类的想法。AI融进我们的生活有很多可能它会不会取代人类。但我们现在越来越清楚地看到，很可能将来的强人工智能不怎么像人，甚至跟人完全不同，其思维方式从底层开始就跟人分道扬镳，就可能出现有一天人类跟AI讲伦理的时候，已经讲不通了。</key_sentence></doc>